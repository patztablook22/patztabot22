{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4774140d-0ae8-4e1f-b3cc-e3f86c7aadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import IPython\n",
    "\n",
    "sys.path.append(\"../src/utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e42a3c-e2e2-4e23-8bac-85eca8ed3c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport datasets\n",
    "%aimport general\n",
    "%aimport training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbba8b45-442e-4195-9eab-20cf24f7ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b33f3d-d255-46eb-9de8-0c091ca60ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_path = '../data/tokenized-gpt2.pkl'\n",
    "\n",
    "import pickle\n",
    "with open(tokenized_path, 'rb') as f:\n",
    "    tokenized = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11df7c25-c208-4d1a-b880-5bd4cde0be1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta 12 s\n"
     ]
    }
   ],
   "source": [
    "# variable context size does not make sense (?)\n",
    "# model predicts 1st token 2nd token ... all positions independently while attending only to prior positions\n",
    "# therefore the model practices both short and long contexts\n",
    "\n",
    "ds_train = training.MaskedDataset(tokenized, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69339aa-18ab-4f05-934d-779277c57c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8952"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5a45a9-0c15-435c-9452-7743b4598088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   79,    25,   220, 50257,   198,    83,  1219,   293,   334,   129,\n",
       "          122,   497, 50256,   198,    79,    25,   220, 50257,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,    57,    21, 50256,   198,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,    79,    25,   220, 50257,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   893, 50256,\n",
       "          198,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,   220,\n",
       "        50257,   198, 50256,   198,    79,    25,   220, 50257,   628, 50256,\n",
       "          198,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,\n",
       "           25,   220, 50257,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,    73, 50256,   198,    79,    25,\n",
       "          220, 50257,   198, 50256,   198,    79,    25,   220, 50257,   198,\n",
       "        50256,   198,    79,    25,   220, 50257,   198, 50256,   198,    79,\n",
       "           25,   220, 50257,   198, 50256,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,    79,    25,   220,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,    79,    25,   220,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,    79,    25,   220,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,    79,    25,   220,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,    79,    25,   220,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,    79,    25,   220, 50257,   628,   198,   198,   198,\n",
       "          198,  1925,   359, 40210,   284, 27574,  1338, 35812,  2449, 48590,\n",
       "         6544,   952,   284, 50256,   198,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,    79,    25,   220, 50257,   198,    45,\n",
       "         1453,    68,   198,    47,   129,   247,  3762, 32790,   466,   350,\n",
       "        11392,    88,    30, 50256,   198,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,\n",
       "           25,   220, 50258, 43074,    97, 37929, 50256,   198,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,    79,    25,   220, 50257,   198, 10434,\n",
       "          276,   257,   869,   326, 15436,  1367,  2431,    13, 50256,   198,\n",
       "           79,    25,   220, 50257,   198,    89,   615,   349,  6557,    76,\n",
       "         1976, 37302,    84,   299,   128,   249,    73,   461,   497,    69,\n",
       "         2150,    84, 18015, 12314,  4686,    74, 50256,   198,    79,    25,\n",
       "          220, 50257,   198,    89,   615,   349,  6557,    76,   279,   129,\n",
       "          247,   274, 31228, 50256,   198,    79,    25,   220, 50257,   198,\n",
       "           44,   680,    78,   198,    53,    88,  6513,   129,    98, 21504,\n",
       "        38836,   458,    82,   198, 40932,   410,  2376,   129,   122,  6988,\n",
       "           72,   410,   276,   293,  1281, 11129, 12385, 16667,   778, 15418,\n",
       "           84, 50256,   198,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           79,    25,   220, 50257,   198,    43,   349,   198, 25492,   497,\n",
       "         8457,    72,   337, 19388, 50256,   198,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,    79,    25,   220,   198,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           79,    25,   220, 50258, 43074,    97, 37929,   198, 50257,   198,\n",
       "         2777,   349,    84, 11223, 32790,    83,   128,   249,   410,    88,\n",
       "          129,   247,    68, 32790,  8836,  1326, 12777,   340,  6557,    75,\n",
       "         4178,   198,    76,   128,   249,   573,   128,   237,   745,    89,\n",
       "         2100,   474, 31829,  1534,   274,   273, 12385,   284,    71,   293,\n",
       "          198,   198,    19,    13, 11223, 16723,   128,   249,    75,  8836,\n",
       "          198,  1219,  5089,   198,    77, 14761,   256,   461,   284, 12385,\n",
       "         3478,  8156, 12938,   497,    73, 15532, 50256,   198,    79,    25,\n",
       "          220, 50257,   198,    73, 43616,   616, 26738,    75, 25370,   122,\n",
       "           68,   284, 11223,  6184,   118,   353,   127,   121,   198,   129,\n",
       "          122,    68,   416,   354,   384, 21885,   285, 48988,   288,   455,\n",
       "          265,   279,   129,   247,   274,   299,   420,   198,    73, 25496,\n",
       "         1976, 16723,   128,   249,    75,  8836,  1569, 46195,   263, 12385,\n",
       "         6184,   118,   353,   127,   121,   374,  6557,  3919,   198,  3448,\n",
       "        32790,  5439, 21504,   284,   277,  1228,    77,    11, 25370,   122,\n",
       "           68,   416, 21504,   284,   289,  6335, 10102,   555,    72,  2124,\n",
       "           35, 50256,   198,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,    79,    25,   220,   198,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,\n",
       "          220, 50257,   198,  1676,   301,   128,   249,  9552,    12,  5363,\n",
       "        47594,   344,   604,  7874,    20,    13,   275,   129,   247,  8471,\n",
       "         2616,   410,   299,   128,   249,  1326,   694,    84, 50256,   198,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,\n",
       "          220, 50258, 12520,   240,   222, 50256,   198,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,\n",
       "          220,   198,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,   220,\n",
       "        50257,   198, 20471,   284, 11223,   474, 25496,   129,   122,    68,\n",
       "          264,   448,   128,   249,   129,   122,   198,    83,   321,   474,\n",
       "        13396,   362,   288,  3281,   410,   479,  1904, 50256,   198,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,   220,\n",
       "        50257,   198,    76, 19388,   299,   268,  8836,  2401,    64, 50256,\n",
       "          198,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,\n",
       "           25,   220, 50257,   198,    82,   324,   469, 50256,   198,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,    79,    25,   220,   198,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    79,    25,\n",
       "          220, 50257,   198, 41098,   285,   129,   107,   129,   122,   368,\n",
       "          334,   129,   122,   285,  6557,    76,  3024,   709,   280, 25370,\n",
       "           94,    74,   349,    84,   410,  8836,   344,    76, 35942,   128,\n",
       "          249,   198,    83,   461,   279,   461, 50256,   198,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,    79,    25,   220,   198,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,    79,    25,   220, 50257,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  3720,\n",
       "        50256,   198])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0:3][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27d85edf-30d5-49ba-9ccf-7ac6cfd6de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids <class 'numpy.ndarray'> (962,)\n",
      "attention_mask <class 'numpy.ndarray'> (962,)\n",
      "labels <class 'numpy.ndarray'> (962,)\n",
      "\n",
      "input_ids <class 'numpy.ndarray'> (1024,)\n",
      "attention_mask <class 'numpy.ndarray'> (1024,)\n",
      "labels <class 'numpy.ndarray'> (1024,)\n",
      "\n",
      "input_ids <class 'numpy.ndarray'> (1024,)\n",
      "attention_mask <class 'numpy.ndarray'> (1024,)\n",
      "labels <class 'numpy.ndarray'> (1024,)\n",
      "\n",
      "input_ids <class 'numpy.ndarray'> (1024,)\n",
      "attention_mask <class 'numpy.ndarray'> (1024,)\n",
      "labels <class 'numpy.ndarray'> (1024,)\n",
      "\n",
      "input_ids <class 'numpy.ndarray'> (1024,)\n",
      "attention_mask <class 'numpy.ndarray'> (1024,)\n",
      "labels <class 'numpy.ndarray'> (1024,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ds_train[0:5]:\n",
    "    for k, v in i.items():\n",
    "        print(k, type(v), v.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d3cc8de-4d85-47b2-a3f7-eda691c4e225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'input_ids': tensor([[   79,    25,   220,  ..., 50256, 50256, 50256],\n",
       "         [29615,    25, 23748,  ...,   375,    84, 32790],\n",
       "         [   68, 14561,   709,  ...,   497,    73,    85]]),\n",
       " 'labels': tensor([[  79,   25,  220,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "eos_token_id = 50256\n",
    "coll = training.DataCollator(pad_token_id=eos_token_id)\n",
    "\n",
    "coll(ds_train[0:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
